{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8IHm2PABhFP"
      },
      "source": [
        "<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n",
        "\n",
        "<h1 style=\"text-align: center;\"><b>Домашнее задание. Решение конкурса на kaggle</b></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFXklK63BhFQ"
      },
      "source": [
        "Цель:\n",
        "\n",
        "\n",
        "Задача: сделать предобаботку данных, провести исследовательский анализ и построить модели. Выбрать наилучшую модель, где score >= 0.84. Взять метрику ROC-AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lzLqEeZKEEYz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOlxdURSEEY3"
      },
      "source": [
        "## Загрузка данных. Предобработка данных.\n",
        "\n",
        "На данном этапе необходимо:\n",
        "1) загрузить данные train и test\n",
        "2) проверить данные на пропуски, дубликаты\n",
        "3) при обнаружении пропусков необходимо их заменить, при наличии дубликатов, посмотреть стоит ли их удалять.\n",
        "4) сделать вывод по проделланной предобработке данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XULA1f3ch6RL"
      },
      "outputs": [],
      "source": [
        "!gdown 1ERwQ5odiK1Zvi1LtjpkzCMUswYsAX8_K  # train.csv\n",
        "!gdown 1fGw_-RFwvn_LEdt91Jq-7A-wzG6mmH8r  # test.csv\n",
        "!gdown 199Mt4OYZNaelT83U-HGDsEYs2YcUGQ6y  # submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw-Brue9EEY3"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('./train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgnkkF5bEEY9"
      },
      "outputs": [],
      "source": [
        "# Для вашего удобства списки с именами разных колонок\n",
        "\n",
        "# Числовые признаки\n",
        "num_cols = [\n",
        "    'ClientPeriod',\n",
        "    'MonthlySpending',\n",
        "    'TotalSpent'\n",
        "]\n",
        "\n",
        "# Категориальные признаки\n",
        "cat_cols = [\n",
        "    'Sex',\n",
        "    'IsSeniorCitizen',\n",
        "    'HasPartner',\n",
        "    'HasChild',\n",
        "    'HasPhoneService',\n",
        "    'HasMultiplePhoneNumbers',\n",
        "    'HasInternetService',\n",
        "    'HasOnlineSecurityService',\n",
        "    'HasOnlineBackup',\n",
        "    'HasDeviceProtection',\n",
        "    'HasTechSupportAccess',\n",
        "    'HasOnlineTV',\n",
        "    'HasMovieSubscription',\n",
        "    'HasContractPhone',\n",
        "    'IsBillingPaperless',\n",
        "    'PaymentMethod'\n",
        "]\n",
        "\n",
        "feature_cols = num_cols + cat_cols\n",
        "target_col = 'Churn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHC6gWabEEZA"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK370bPCEEZD"
      },
      "source": [
        "## Анализ данных (3 балла)\n",
        "\n",
        "1) Для численных призанков постройте гистограмму (*plt.hist(...)*) или boxplot (*plt.boxplot(...)*). Для категориальных посчитайте количество каждого значения для каждого признака. Для каждой колонки надо сделать *data.value_counts()* и построить bar диаграммы *plt.bar(...)* или круговые диаграммы *plt.pie(...)* (хорошо, елси вы сможете это сделать на одном гарфике с помощью *plt.subplots(...)*).\n",
        "\n",
        "2) Посмотрите на распределение целевой переменной и скажите, являются ли классы несбалансированными.\n",
        "\n",
        "3) (Если будет желание) Поиграйте с разными библиотеками для визуализации - *sns*, *pandas_visual_analysis*, etc.\n",
        "\n",
        "Второй пункт очень важен, потому что существуют задачи классификации с несбалансированными классами. Например, это может значить, что в датасете намного больше примеров 0 класса. В таких случаях нужно 1) не использовать accuracy как метрику 2) использовать методы борьбы с imbalanced dataset (обычно если датасет сильно несбалансирован, т.е. класса 1 в 20 раз меньше класса 0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZkbgFJZEEZE"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg60u3QDEEZH"
      },
      "source": [
        "(Дополнительно) Если вы нашли какие-то ошибки в данных или выбросы, то можете их убрать. Тут можно поэксперементировать с обработкой данных как угодно, но не за баллы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwfksF1gEEZI"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DviiJd8REEZK"
      },
      "source": [
        "## Применение линейных моделей (3 балла)\n",
        "\n",
        "1) Обработайте данные для того, чтобы к ним можно было применить LogisticRegression. Т.е. отнормируйте числовые признаки, а категориальные закодируйте с помощью one-hot-encoding'а.\n",
        "\n",
        "2) С помощью кроссвалидации или разделения на train/valid выборку протестируйте разные значения гиперпараметра C и выберите лучший (можно тестировать С=100, 10, 1, 0.1, 0.01, 0.001) по метрике ROC-AUC.\n",
        "\n",
        "Если вы разделяете на train/valid, то используйте LogisticRegressionCV. Он сам при вызове .fit() подберет параметр С. (не забудьте передать scroing='roc_auc', чтобы при кроссвалидации сравнивались значения этой метрики, и refit=True, чтобы при потом модель обучилась на всем датасете с лучшим параметром C).\n",
        "\n",
        "\n",
        "(более сложный вариант) Если вы будете использовать кроссвалидацию, то преобразования данных и LogisticRegression нужно соединить в один Pipeline с помощью make_pipeline, как это делалось во втором семинаре. Потом pipeline надо передать в GridSearchCV. Для one-hot-encoding'a можно испльзовать комбинацию LabelEncoder + OneHotEncoder (сначала превращаем строчки в числа, а потом числа првращаем в one-hot вектора.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHCLDmwqEEZL"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2Yv3uYtEEZO"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVahy6JKEEZQ"
      },
      "source": [
        "Выпишите какое лучшее качество и с какими параметрами вам удалось получить"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36729TOQEEZR"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlTeVy7fEEZR"
      },
      "source": [
        "## Применение градиентного бустинга (2 балла)\n",
        "\n",
        "Если вы хотите получить баллы за точный ответ, то стоит попробовать градиентный бустинг. Часто градиентный бустинг с параметрами по умолчанию даст вам 80% результата за 0% усилий.\n",
        "\n",
        "Мы будем использовать catboost, поэтому нам не надо кодировать категориальные признаки. Catboost сделает это сам (в .fit() надо передать cat_features=cat_cols). А численные признаки нормировать для моделей, основанных на деревьях не нужно.\n",
        "\n",
        "1) Разделите выборку на train/valid. Протестируйте catboost cо стандартными параметрами.\n",
        "\n",
        "2) Протестируйте разные занчения параметров количества деревьев и learning_rate'а и выберите лучшую по метрике ROC-AUC комбинацию.\n",
        "\n",
        "(Дополнительно) Есть некоторые сложности с тем, чтобы использовать CatBoostClassifier вместе с GridSearchCV, поэтому мы не просим использовать кроссвалидацию. Но можете попробовать)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fioxxlp-EEZS"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf4Kjt96EEZU"
      },
      "source": [
        "Выпишите, какое лучшее качество и с какими параметрами вам удалось получить"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2d9GolXEEZV"
      },
      "source": [
        "ВАШ ОТВЕТ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDMXbvNZEEZV"
      },
      "source": [
        "# Предсказания"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_P4wFNaEEZW",
        "outputId": "1fba5dfc-88e4-49e3-ed8a-afe21ae3325a"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-12-7d881febecc7>, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-7d881febecc7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    best_model = # какая-то предыдущая модель\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "best_model = # какая-то предыдущая модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfSufx0CEEZZ"
      },
      "outputs": [],
      "source": [
        "X_test = pd.read_csv('./test.csv')\n",
        "submission = pd.read_csv('./submission.csv')\n",
        "\n",
        "submission['Churn'] = # используйте best_model.predict_proba(X_test), не забудьте выделить вероятность класса 1.\n",
        "submission.to_csv('./my_submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzGirrp5l2I-"
      },
      "source": [
        "Лучшее решение отправьте в Stepik."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoNce9Yu0OM5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}